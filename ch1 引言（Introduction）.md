我们已无可争议地迈入加速计算的时代。为满足全球对更强算力的无尽渴求，<font style="background-color:#E8F7CF;">加速计算通过提供比早期解决方案更高的性能与更优的能效</font>，驱动着复杂模拟、人工智能等众多领域的突破。 

被誉为“计算机架构的新黄金时代”的我们，正面临着由多样化计算设备带来的巨大机遇。为实现加速计算的全面潜力，我们需要不依赖于任何单一供应商或架构的可移植软件开发能力。  

SYCL（发音同“sickle”）是由行业推动的Khronos Group标准，旨在通过C++为加速（异构）系统提供高级数据并行支持。该标准为C++编译器提供了与现代C++及C++构建系统高度协同的机制，以充分利用加速（异构）系统。SYCL并非首字母缩写词，仅作为专有名称使用。  

>  **加速 vs. 异构**
>
> 这些术语相辅相成。"异构性"是一个技术性描述，承认了采用不同编程方式的计算设备的组合。"加速"则是为系统和编程引入这种复杂性的动机。但加速从无保证；只有当我们正确编程时，异构系统才能加速我们的应用程序。本书正是为了教会我们如何正确实现这一目标！  
>

<font style="background-color:#FBE4E7;">采用 SYCL 实现的 C++ 数据并行技术可访问现代加速（异构）系统中的所有计算设备</font>。单个 C++ 应用程序能够灵活调用适用于当前任务的任意设备组合——包括图形处理器、中央处理器、现场可编程门阵列及专用集成电路等。任何单一厂商的专有解决方案都无法提供同等程度的灵活性。  

本书向我们传授如何通过C++与SYCL实现数据并行编程来驾驭加速计算，并就如何平衡应用程序性能、跨计算设备的可移植性以及程序员自身的工作效率提供了实用建议。本章通过阐述核心概念（包括关键术语）奠定基础，这些内容在我们学习利用数据并行性加速C++程序时需要时刻牢记于心。  

## "读书，不读说明书"（Read the Book, Not the Spec）  
没有人愿意听到"去读规范文档！"这样的话——规范文档通常艰涩难懂，SYCL规范(www.khronos.org/sycl/)也不例外。与所有优秀的编程语言规范一样，它虽然精确详尽，却在设计动机、使用方法和教学指导方面着墨不多。本书正是以SYCL为工具教授C++的"学习指南"。  

没有任何一本书能一次性解释所有内容。因此，本章将做其他章节不会做的事：代码示例中包含的编程结构将留待后续章节阐明。我们不必纠结于在第一章就完全理解这些代码示例，相信随着章节推进，理解会逐渐深入。  

##  SYCL 2020与DPC++（SYCL 2020 and DPC++）
本书采用SYCL 2020标准教授C++编程。本书第一版问世于SYCL 2020规范发布之前，故本版进行了多项更新：包括头文件路径调整（使用sycl替代CL）、设备选择器语法变更，以及移除了显式主机设备等内容。  

<font style="background-color:#FBE4E7;">DPC++是一个基于LLVM的开源编译器项目</font>。我们期望SYCL能最终获得LLVM社区的默认支持，而DPC++项目将助力实现这一愿景。该编译器提供广泛的异构计算支持，涵盖GPU、CPU及FPGA。本书所有示例均通过DPC++编译器验证，并应兼容任何支持SYCL 2020标准的C++编译器。  

> 获取SYCL最新信息的重要资源包括：本书的GitHub页面（github.com/Apress/data-parallel-CPP）、Khronos Group SYCL标准官网（www.khronos.org/sycl）以及核心SYCL教育平台（sycl.tech）。这些渠道将提供已知的书籍勘误等更新内容。  
>

截至本书出版时，尚无任何C++编译器宣称完全符合SYCL 2020规范。然而本书代码已在DPC++编译器上验证通过，并应兼容其他实现了SYCL 2020主要特性的C++编译器。我们严格采用标准C++与SYCL 2020进行编写，仅存在三处例外：第17章（FPGA编程）少量标注的DPC++专属扩展、第20章（后端互操作性）涉及Level Zero后端连接的情况，以及尾声部分对未来技术的前瞻性讨论。  

##  为何不选CUDA？（Why Not CUDA?）
与CUDA不同，<font style="background-color:#FBF5CB;">SYCL通过C++实现了对所有厂商和各类架构（不仅限于GPU）的数据并行支持</font>。CUDA仅专注于NVIDIA GPU的支持，尽管HIP/ROCm等方案在复用其代码适配其他厂商GPU方面取得了一定成效，但其成功潜力仍存在局限。随着加速器架构的爆发式增长，唯有SYCL能提供我们所需的支持——驾驭这种多样性并实现多厂商/多架构的解决方案，从而解决CUDA无法实现的移植性问题。若要深入理解这一动机，我们强烈推荐阅读（或观看其精彩演讲视频）计算机体系结构行业传奇人物John L. Hennessy与David A. Patterson合著的《计算机体系结构的新黄金时代》，我们认为这是一篇必读文献。  

第21章除了涵盖有助于将代码从CUDA迁移至SYCL C++的内容外，对于熟悉CUDA的开发者也极具价值——它能弥合术语与功能差异。<font style="background-color:#FBE4E7;">SYCL超越CUDA的核心优势在于</font>：<font style="background-color:#E8F7CF;">支持多厂商硬件、多架构设备（不限于GPU），甚至为同一设备提供多后端支持</font>。这种灵活性正是对"为何不继续使用CUDA？"的最佳回应。  

与CUDA或HIP相比，<font style="background-color:#E8F7CF;">SYCL不会引入任何额外开销</font>。它并非兼容层——而<font style="background-color:#E8F7CF;">是一种通用化方案，向所有厂商和架构的设备开放，同时保持与现代C++同步</font>。与其他多厂商、多架构的开放式技术（如OpenMP和OpenCL）一样，其最终验证在于具体实现方案，包括必要时访问硬件特定优化功能的选项。  

##  为何选择标准C++与SYCL？（Why Standard C++ with SYCL?）
正如我们将反复指出的，<font style="background-color:#FBE4E7;">所有使用SYCL的程序首先都是一个C++程序</font>。SYCL并不依赖对C++语言本身的任何修改，而是将C++编程带入其原本无法涉足的领域。我们毫不怀疑加速计算编程将持续影响包括C++在内的语言标准发展，但我们认为C++标准不应（也不会）在短期内进化到能取代SYCL的地步。SYCL拥有丰富的能力体系——这正是本书所要详述的内容——它通过类体系扩展C++功能，并针对多厂商多架构支持（这一当前已存在的需求）提供了完备的新编译器能力支持。  

##  获取支持SYCL的C++编译器（Getting a C++ Compiler with SYCL Support）
本书中的所有示例均能在各种不同版本的DPC++编译器下编译并运行，也应支持其他符合SYCL标准的C++编译器（参见www.khronos.org/sycl网站"开发中的SYCL编译器"章节）。我们已审慎标注出版时仅适用于DPC++的少量扩展功能使用情况。  

作者推荐使用DPC++编译器有诸多原因，包括我们与DPC++编译器的紧密合作。<font style="background-color:#FBE4E7;">DPC++是一个支持SYCL标准的开源编译器项目</font>。通过采用LLVM框架，DPC++编译器项目能够适配多种设备的后端，目前已实现对英特尔、英伟达和AMD显卡、多款CPU以及英特尔FPGA的支持。这种能公开扩展并增强多厂商、多架构兼容性的特性，使得LLVM成为支持SYCL开源项目的理想选择。  

存在多个版本的DPC++编译器，它们通过额外工具和库进行了增强，作为支持异构系统的大型项目组成部分提供广泛支持。这些支持包括各类库、第1章 引言6调试器及其他工具，统称为oneAPI项目。其中包含DPC++编译器在内的oneAPI工具均可免费获取（www.oneapi.io/implementations）。  

```cpp

```

## 你好，世界！及SYCL程序解析（Hello, World! and a SYCL Program Dissection）
图1-1展示了一个SYCL程序示例。编译并运行该程序将输出以下内容：  

Hello, world!（以及一些需要通过运行来体验的额外文本）我们将在第四章结束时完全理解这个示例。在此之前，我们可以观察到仅需包含`<sycl/sycl.hpp>`头文件（第2行），该文件定义了所有SYCL结构。所有SYCL结构都位于名为`sycl`的命名空间内。  

+ 第3行让我们避免反复书写"sycl::"。 
+ 第12行实例化了一个指向特定设备的工作请求队列（参见第2章）。 
+ 第14行创建了与设备共享的数据分配空间（参见第3章）。 
+ 第15行将加密字符串复制到设备内存中，后续将由内核处理。 
+ 第17行将工作任务加入设备队列（参见第4章）。 
+ 第18行是唯一会在设备上运行的代码行，其余代码均在主机（CPU）端执行。  

第18行是我们希望在设备上运行的核心代码。该核心代码执行单个字符的递减操作。借助parallel_for()的并行能力，该内核会在秘密字符串的每个字符上运行，从而将其解码为结果字符串。这些工作无需特定执行顺序，且一旦parallel_for将任务加入队列，内核便会相对于主程序异步运行。在使用统一共享内存（第6章将介绍）这一便捷特性时，务必在查看结果前执行等待操作（第19行），以确保内核已完成运算，这一点至关重要。若缺少等待，程序可能会在所有字符完成解密前就输出结果。后续章节将展开更深入的探讨。  

##  队列与操作（Queues andActions）
第二章将讨论队列与操作，但目前我们可以从一个简单的解释开始。<font style="background-color:#FBE4E7;">队列是允许应用程序向设备分配待执行工作的唯一连接方式</font>。<font style="background-color:#FBF5CB;">队列中可放置两种操作类型</font>：（a）<font style="background-color:#E8F7CF;">待执行代码</font>；（b）<font style="background-color:#E8F7CF;">内存操作</font>。待执行代码通过`single_task`或`parallel_for`（如图1-1所示）来表达。<font style="background-color:#FDE6D3;">内存操作</font>则<font style="background-color:#E8F7CF;">负责主机与设备间的复制操作或初始化内存的填充操作</font>。<font style="background-color:#E8F7CF;">只有当我们需要比自动处理更精细的控制时，才需显式使用内存操作</font>。这些内容都将在第二章开始的后续章节详细讨论。现在我们需要明确：<font style="background-color:#FBE4E7;">队列是允许我们控制设备的连接机制</font>，我们有一系列可用于队列的操作来执行代码和转移数据。尤其重要的是，请求的操作会被立即放入队列而无需等待。主机将操作提交至队列后，程序会继续执行，而设备最终将通过队列异步执行请求的操作。  

>  队列将我们与设备相连  
>
>  我们将操作提交至队列以请求计算任务和数据迁移。这些操作以异步方式执行。  
>

## 并行计算：一切皆为并行（It Is All About Parallelism）
由于用C++实现数据并行编程的核心在于并行性，我们先从这一关键概念讲起。并行编程的目标在于<font style="background-color:#FDE6D3;">加速计算过程</font>，这实际上涉及两个维度：<font style="background-color:#E8F7CF;">提升吞吐量</font>与<font style="background-color:#E8F7CF;">降低延迟</font>。  

###  吞吐量（Throughput）  
<font style="background-color:#E8F7CF;">程序吞吐量的提升体现在单位时间内完成更多工作</font>。诸如流水线等技术可能会延长单个工作项的完成时间，但通过实现工作重叠，最终达成单位时间内更高的任务处理量。这种现象在人类协作中十分常见——分工本身需要协调成本，这往往会减缓单项工作的完成速度，然而多人协作的力量却能带来更高的整体产出。计算机系统亦遵循相同原理：<font style="background-color:#E8F7CF;">将任务分配至更多处理核心虽然会增加每个工作单元的协调开销并可能引发延迟，但通过多个处理核心的协同运作，我们的根本目标仍是实现更高总量的任务完成</font>。  

###  延迟（Latency）
若我们想要更快完成某项任务——例如分析语音指令并生成响应？若仅关注吞吐量，响应时间可能变得难以忍受。<font style="background-color:#FBE4E7;">降低延迟的理念要求</font>我们<font style="background-color:#E8F7CF;">将工作任务拆分为可并行处理的单元</font>。就吞吐量而言，图像处理可能将整幅图像分配给不同处理单元——此时我们的目标或许是优化每秒处理图像数。而对于延迟，图像处理可能将单幅图像中的每个像素分配给不同处理核心——此时我们的目标则可能是最大化单幅图像的每秒处理像素数。  

###  思并行（Think Parallel）
成功的并行程序员在编程中同时运用这两种技术。这正是我们"并行思维"探索之旅的开端。  

我们希望调整思维方式，<font style="background-color:#FBE4E7;">首先关注算法和应用中可发掘并行性的位置</font>，同时<font style="background-color:#FBE4E7;">思考不同的并行表达方式如何影响最终实现的性能</font>。这一认知过程需要逐步消化。对于并行程序员而言，"并行思维"的探索将成为毕生之旅。在此，我们可以掌握若干实用技巧。  

###  阿姆达尔和古斯塔夫森（Amdahl and Gustafson）
由超级计算机先驱吉恩·阿姆达尔于1967年提出的**阿姆达尔定律**，是一种用于预测多处理器系统理论最大加速比的公式。阿姆达尔曾遗憾地指出：<font style="background-color:#FBE4E7;">并行化带来的最大收益受限于(1/(1-p))</font>，其中p代表程序中可并行执行部分的比例。若仅对程序的三分之二进行并行化处理，则该程序的最大加速比仅为3倍。我们必须深刻理解这一概念！其根源在于，无论我们将那三分之二的程序优化得多快，剩余三分之一串行部分的执行时间始终不变。即便增加100块GPU，性能提升幅度仍止步于3倍。  

多年来，一些人将此视为并行计算难以取得成效的佐证。1988年，约翰·古斯塔夫森（John Gustafson）发表了题为《重新评估阿姆达尔定律》的论文。他指出<font style="background-color:#FBE4E7;">并行技术的价值不在于加速固定工作负载，而在于实现任务规模的扩展</font>。这种现象与人类活动如出一辙：一名快递员即便获得更多人员和卡车的协助，也无法更快投递单个包裹；但百名司机驾驶百辆卡车，必然比单人单车能更快完成百件包裹的投递——多司机系统不仅能显著提升吞吐量，通常还能降低包裹投递的延迟。阿姆达尔定律告诉我们，为投递单个包裹而额外配备九十九名司机和卡车毫无意义；而古斯塔夫森则洞察到，利用这些额外资源完全可以实现百件包裹的加速投递。  

这强调了并行性之所以最有价值，是因为我们处理的问题规模逐年持续增长。如果我们年复一年只是希望更快地运行相同规模的问题，那么研究并行性就远没有那么重要。正是这种解决日益庞大问题的追求，推动了我们对利用数据并行性的兴趣——通过采用C++与SYCL相结合的方式——为计算机（异构/加速系统）的未来发展铺路。  

###  扩展（Scaling）
“扩展性”（scaling）一词曾在我们先前的讨论中出现。<font style="background-color:#FBE4E7;">扩展性</font>是<font style="background-color:#E8F7CF;">衡量程序在获得额外计算资源时加速程度（简称为“加速比”）的指标</font>。理想加速比表现为：若用一百辆卡车与驾驶员替代单辆卡车，能在相同时间内完成一百件包裹而非一件包裹的配送。当然，现实往往并非如此简单。系统总会在某个环节出现限制加速比的瓶颈——例如配送中心可能没有足够供百辆卡车同时停靠的泊位。计算机程序中，瓶颈常出现在数据向处理单元传输的过程中。向百辆卡车分配任务，类似于将数据分发至百个处理核心，而分发行为本身并非瞬时完成。第三章将开启我们在异构系统中探索数据精准分发的旅程。必须清醒认识到：数据分发存在成本，这一成本直接影响着应用程序所能实现的扩展性上限。  

###  异构系统（Heterogeneous Systems）
就我们的研究目的而言，<font style="background-color:#FBE4E7;">异构系统</font>是<font style="background-color:#E8F7CF;">指包含多种类型计算设备的系统</font>。例如，同时配备中央处理器（CPU）和图形处理器（GPU）的系统即属于异构系统。虽然CPU通常简称为处理器，但当我们将异构系统中所有处理单元统称为计算处理器时，这种简称可能引发歧义。为避免混淆，<font style="background-color:#E8F7CF;">SYCL标准将处理单元统称为设备</font>。<font style="background-color:#CEF5F7;">应用程序始终运行在主机上，再由主机向各设备分配计算任务</font>。第二章将开始探讨主程序（主机代码）如何引导计算任务在异构系统中定向分配到特定设备。  

采用C++与SYCL编写的程序在主机上运行，并向设备提交工作内核。尽管看似矛盾，但必须明确：<font style="background-color:#FBE4E7;">主机通常也能作为设备使用</font>。这一特性具有两大关键价值：(1) 当系统未配备加速器时，作为CPU的主机可直接执行内核——这实现了SYCL确保应用可移植性的核心承诺：<font style="background-color:#E8F7CF;">即使在没有加速器的系统上，内核仍能可靠运行</font>；(2) 现代CPU往往具备向量/矩阵/张量运算及AI处理能力，这些本质上都是内核可高效映射运行的加速器单元。  

> 主机代码调用设备上的代码。主机的功能通常也可作为设备使用，既提供备用设备，又能利用主机本身对处理内核的加速能力。我们的主机通常为CPU，因此它也可能作为CPU设备使用。<font style="background-color:#E8F7CF;">SYCL不保证存在CPU设备，仅承诺应用程序至少有一个可用设备作为默认设备</font>。  
>

虽然“异构”是从技术角度对系统的描述，但我们之所以使硬件和软件复杂化，正是为了获得更高的性能。因此，“加速计算”这一术语在推广异构系统或其组件时广受欢迎。需要强调的是，加速并非必然——<font style="background-color:#FBE4E7;">唯有正确编程，异构系统才能真正实现应用加速</font>。本书正是要教会我们如何做到这一点！  

 图形处理器（GPU）已发展成为高性能计算（HPC）设备，因此有时被称为通用图形处理器（GPGPU）。出于异构编程的目的，我们可以简单地假设我们正在对这类强大的GPGPU进行编程，并将其简称为GPU。  

 当今，异构系统中的设备集合可包括中央处理器（CPU）、图形处理器（GPU）、现场可编程门阵列（FPGA）、数字信号处理器（DSP）、专用集成电路（ASIC）以及人工智能芯片（如图形芯片、神经形态芯片等）。  

这类设备的设计将涉及计算处理器（多处理器）的复制以及到数据源（如内存）的连接增加（带宽提升）。其中，多处理技术对提高吞吐量尤为有效——类比中通过增加驾驶员与卡车数量实现；而更高的数据带宽则对降低延迟至关重要——类比中通过增设并行装载码头使卡车可同时满载完成。  

拥有<font style="background-color:#FBF5CB;">多种类型的设备，每种设备具有不同的架构因而呈现出不同的特性</font>，<font style="background-color:#E8F7CF;">这导致针对每种设备需要采用不同的编程和优化方法</font>。正是这一点构成了SYCL C++的核心理念，也是本书主要阐述的内容。  

> SYCL的创立旨在解决面向异构（加速）系统的C++数据并行编程难题。  
>

###  数据并行编程(Data-Parallel Programming)
自本书标题出现以来，"数据并行编程"这一术语始终未经阐释。<font style="background-color:#FBE4E7;">数据并行编程的核心</font>在于<font style="background-color:#E8F7CF;">将并行性视作对大量数据同时进行操作</font>。这种视角转变犹如Gustafson定律之于Amdahl定律——正如我们需要分派一百个包裹（实质是海量数据）给一百辆配备司机的卡车来分配工作。关键问题归结于划分对象的选取：应当整体处理图像，还是分块处理，抑或逐像素处理？是将对象集合作为整体分析，还是划分为子集处理，或者逐个对象处理？  

<font style="background-color:#FBF5CB;">选择恰当的工作划分方式并将其有效地映射到计算资源上，是每位使用C++与SYCL进行并行编程的开发者的职责</font>。第4章将开启这一议题的讨论，后续章节将持续深入展开。  

##  SYCL 中 C++ 的关键特性(Key Attributes of C++ with SYCL)
<font style="background-color:#FBE4E7;">使用SYCL的每个程序首先都是一个C++程序</font>。<font style="background-color:#E8F7CF;">SYCL并不依赖于对C++语言进行任何修改</font>。  

<font style="background-color:#E8F7CF;">支持SYCL的C++编译器将基于对SYCL规范的内置知识进行代码优化，同时实现异构编译功能，使其能在传统C++构建系统中"开箱即用"</font>。  

接下来，我们将阐释<font style="background-color:#FBE4E7;">SYCL框架下C++的核心特性</font>：<font style="background-color:#E8F7CF;">单源代码模式（single-source style）</font>、<font style="background-color:#E8F7CF;">主机端（host）</font>、<font style="background-color:#E8F7CF;">设备端（devices）</font>、<font style="background-color:#E8F7CF;">内核代码（kernel code）</font>以及<font style="background-color:#E8F7CF;">异步任务图（asynchronous task graphs）</font>。  

###  单一来源(Single-Source)
程序采用单一源码形式，即<font style="background-color:#D9EAFC;">同一翻译单元既包含定义设备端执行计算内核的代码，也包含协调这些计算内核执行的主机端代码</font>。第2章将首先深入探讨这一特性。虽然我们仍可根据需要将程序源码划分为主机端与设备端的不同文件和翻译单元，但关键在于——这种划分并非必要！  

### 主机(Hsot)
<font style="background-color:#FBE4E7;">每个程序最初都在主机上运行，且程序中大部分代码通常是为主机编写的</font>。迄今为止，<font style="background-color:#FBE4E7;">主机始终是CPU</font>。虽然标准并未强制要求，因此我们谨慎地称之为主机。这种情况似乎不太可能改变，因为<font style="background-color:#CEF5F7;">主机需要完整支持C++17标准才能运行所有基于SYCL的C++程序</font>。稍后将看到，<font style="background-color:#E8F7CF;">设备（加速器）则无需支持完整的C++17功能</font>。

### 设备（Device）
在程序中使用多种设备正是异构编程的本质。这也是自前文对异构系统的解释以来，"设备"一词在本章反复出现的原因。我们已经了解到，<font style="background-color:#FBE4E7;">异构系统中的设备集合</font>可以包括<font style="background-color:#E8F7CF;">GPU、FPGA、DSP、ASIC、CPU和AI芯片等，但并不限于任何固定清单</font>。  

<font style="background-color:#FBF5CB;">设备是获得加速的目标对象</font>。<font style="background-color:#FBE4E7;">计算传输的核心思想</font>是<font style="background-color:#E8F7CF;">将工作任务转移到能够加速其完成的设备上</font>。我们必须考虑如何<font style="background-color:#FBF5CB;">弥补数据传输所损耗的时间</font>——这是一个需要时刻关注的关键议题。 

#### 共享设备（Sharing Devices）
在配备有诸如GPU等设备的系统上，我们可以设想有两个或多个程序同时运行并希望使用同一设备的情况。这些程序未必都采用SYCL框架。若当前有另一个程序正在占用设备，其他程序可能会遭遇处理延迟。这本质上与常规C++程序在CPU上的运行理念相同——倘<font style="background-color:#FBF5CB;">若我们在CPU上同时运行过多活跃程序（如邮件客户端、浏览器、病毒扫描、视频编辑、图像处理等），任何系统都可能出现过载现象</font>。

在超级计算机上，当节点（CPU及其所有连接设备）被独占分配给单一应用时，资源共享通常无需考虑。而在非超级计算机系统中，我们只需注意：<font style="background-color:#FBE4E7;">当多个应用同时使用相同设备时，程序性能可能会受到影响</font>。

一切仍正常运行，我们也无需以不同方式进行编程。  

### 内核代码（Kernel Code）
<font style="background-color:#FBE4E7;">设备代码被指定为内核（kernels）</font>。这一概念并非SYCL C++独有：它同样是OpenCL和CUDA等其他异构加速语言的核心概念。虽然它不同于面向循环的编程方法（如OpenMP目标传输常用的方式），但其代码结构可能类似于最内层循环体，且无需程序员显式编写循环嵌套。

内核代码存在特定限制以支持更广泛的设备兼容性与大规模并行计算。内核代码不支持的特性包括：动态多态、动态内存分配（因此无法使用new或delete运算符进行对象管理）、静态变量、函数指针、运行时类型信息（RTTI）以及异常处理。内核代码中不允许调用虚成员函数与可变参数函数，且禁止出现递归调用。

> ** 虚拟函数 ** 
>
> 尽管本书不再深入探讨，但DPC++编译器项目确实包含一项实验性扩展功能（开源项目中可见），旨在为内核中的虚函数提供部分支持。由于高效传输至加速器的特性，虚函数在无限制条件下难以得到良好支持，但许多用户表示希望看到SYCL即使存在限制也能提供此类功能。开源之美及SYCL开放标准的优势，在于能够参与可能影响C++与SYCL标准未来发展的实验。更多信息请访问dpC++项目(github.com/intel/llvm)。
>

第三章阐述了在内核调用前后如何进行内存分配，以确保内核专注于大规模并行计算。第五章探讨了与设备相关的异常处理机制。  

内核中可自由使用C++其余特性，包括函子、lambda表达式、运算符重载、模板、类及静态多态。我们还能与主机共享数据（参见第三章），并通过lambda表达式捕获（非全局）主机变量的只读值。

#### 核心：向量加法（DAXPY）（Kernel: Vector Addition (DAXPY)）
任何编写过计算密集型代码的程序员都会对核函数（kernel）感到熟悉。以经典的DAXPY（双精度A乘以X加Y）实现为例——这个数十年来经久不衰的例程在图1-2中分别用现代Fortran、C/C++和SYCL语言呈现。令人惊叹的是，实际计算行（第3行）的代码几乎完全一致。第4章和第10章将详细解析核函数的概念，而图1-2足以消除"核函数难以理解"的顾虑——即便术语陌生，其代码结构也会令人倍感亲切。

```cpp
! Fortran loop
do i = 1, n
    z(i) = alpha * x(i) + y(i)
end do
// C/C++ loop
for (int i=0; i<n; i++) {
    z[i] = alpha * x[i] + y[i];
}
// SYCL kernel
q.parallel_for(range(n), [=](id<1> i) {
    z[i] = alpha * x[i] + y[i];
}).wait();
```

### 异步执行（Asynchronous Execution）
使用SYCL进行C++编程的异步特性不容忽视。理解异步编程至关重要，原因有二：（1）正确运用可提升性能（实现更优扩展性）；（2）操作失误会导致并行编程错误（通常是竞态条件），致使应用程序不可靠。

异步性的本质在于：工作通过一个请求操作的“队列”被转移到设备上执行。<font style="background-color:#E8F7CF;">主程序将请求的操作提交至队列后，无需等待任何结果即可继续运行</font>。这种无需等待的特性至关重要，它能<font style="background-color:#E8F7CF;">确保计算资源（设备和主机）始终保持忙碌状态</font>。若必须等待，则会束缚主机资源，使其无法执行有效工作；还会在设备完成当前任务后形成串行瓶颈，直至新任务被加入队列。如前所述，阿姆达尔定律会对未实现并行计算的时间段施加惩罚。我们必须构建这样的程序：<font style="background-color:#FBF5CB;">在设备忙于计算时持续进行数据传输，并确保设备和主机的所有计算能力在任务可执行时始终处于饱和状态</font>。若未能做到这一点，我们将彻底承受阿姆达尔定律的惩罚。 

第三章开始讨论将我们的程序视为异步任务图，而第八章则对这一概念进行了大幅扩展。

### 出错时的竞态条件（Race Conditions When We Make a Mistake）
在我们第一个代码示例（图1-1）中，第19行特意设置了"wait"操作，以防止第21行在result值可用之前就将其输出。我们必须时刻牢记这种异步行为特性。同一代码示例中还隐藏着另一个精妙设计——第15行使用std::memcpy加载输入数据。由于std::memcpy在主机端运行，第17行及后续代码必须等待第15行完成才能执行。在学习了第3章后，我们可能会想改用q.memcpy（使用SYCL）。图1-3第7行正是这样修改的。但由于这是队列提交操作，无法保证其会在第9行之前执行，从而产生了竞态条件——这类并行编程特有的缺陷。<font style="background-color:#FBF5CB;">当程序中两个未协调的部分访问同一数据时，就会形成竞态条件</font>。鉴于我们期望通过第7行写入数据后在第9行读取，必须防止第9行先于第7行完成执行的情况发生！此类<font style="background-color:#FBE4E7;">竞态条件将导致程序运行结果不可预测</font>——<font style="background-color:#E8F7CF;">同一程序在不同运行环境和系统中可能产生不同结果</font>。解决方案之一是在第7行末尾显式添加.wait()，强制等待q.memcpy操作完成。但这并非最佳方案，我们还可以通过事件依赖（第8章）来解决。若将队列创建为有序队列，也能在memcpy与parallel_for之间建立隐式依赖关系。此外，第7章将介绍如何利用缓冲区和访问器编程模式，让SYCL自动管理依赖关系与等待操作。

```cpp
// ...we are changing one line from Figure 1-1
char* result = malloc_shared<char>(sz, q);

// Introduce potential data race! We don't define a
// dependence to ensure correct ordering with later
// operations.
q.memcpy(result, secret.data(), sz);

q.parallel_for(sz, [=](auto& i) {
    result[i] -= 1;
}).wait();

// ...
```

>  **竞争条件并不总会导致程序失效。**  
>
>  一位敏锐的读者发现，图1-3中的代码并非在所有测试系统上都会失效。当使用partition_max_sub_devices==0的GPU时，由于该小型GPU无法在内存拷贝完成前执行parallel_for循环，故障并未显现。但代码仍存在缺陷——竞态条件确实存在，即便它不会在每次运行时都触发故障。我们将这种现象称为"竞赛"：有时成功，有时失败。此类编码缺陷可能长期潜伏，直至特定的编译环境与运行时条件组合导致可观测的故障。  
>

 <font style="background-color:#FBE4E7;">添加</font>`<font style="background-color:#FBE4E7;">wait()</font>`<font style="background-color:#E8F7CF;">会强制主机在</font>`<font style="background-color:#E8F7CF;">memcpy</font>`<font style="background-color:#E8F7CF;">和内核之间进行同步</font>，这与之前“保持设备持续忙碌”的建议背道而驰。本书大部分内容探讨了各种方案与权衡，以平衡程序简洁性与系统资源的高效利用。  

> 乱序队列 vs. 顺序队列
>
>  本书将采用乱序队列（out-of-order queues），因其具备潜在的性能优势，但需注意顺序队列（in-order queues）同样存在支持。<font style="background-color:#E8F7CF;">顺序性仅是创建队列时可请求的属性</font>。CUDA程序员应当知晓，<font style="background-color:#CEF5F7;">CUDA流（streams）强制采用顺序执行模式</font>，而<font style="background-color:#FBF5CB;">SYCL队列默认采用乱序模式——但通过在创建SYCL队列时传递</font>`<font style="background-color:#FBF5CB;">in_order</font>`<font style="background-color:#FBF5CB;">属性（参见第8章），可将其设为顺序队列</font>。针对从CUDA转型的程序员，第21章将详述此类特性及其他注意事项。  
>

如需协助检测程序中（包括内核）的数据竞争条件，可使用诸如Intel Inspector（可通过前文“获取DPC++编译器”章节提及的oneAPI工具包获取）等工具。这类工具采用的精密检测方法通常无法适用于所有设备。检测数据竞争条件的最佳实践可能是让所有内核在CPU上运行，这可作为开发阶段的调试技术。该调试技巧在第2章"方法#2"中有详细讨论。

>  为阐释死锁概念，"哲学家就餐问题"是计算机科学中同步问题的经典范例。  
>
>  设想一群哲学家围坐在圆桌旁，每两位哲学家之间摆放着一根筷子。每位哲学家需要两根筷子才能用餐，且他们总是每次只拿起一根筷子。遗憾的是，若所有哲学家都先拿起左侧的筷子，继而握持等待右侧的筷子，当众人同时感到饥饿时便会陷入困境——具体而言，他们将永远等待着那根永远无法获得的筷子。  
>
> 不良的算法设计（例如先拿左叉再等待右叉）在这种情况下可能导致死锁，使得所有哲学家活活饿死。这实在令人遗憾。探讨如何设计出减少哲学家饿死概率的算法——或更理想地实现公平分配、确保所有哲学家都能就餐（无人挨饿）——是个既有趣又经久不衰的研究课题。
>
> 认识到此类编程错误极易发生、在调试时主动排查它们、并逐渐掌握规避技巧，这些都是成为高效并行程序员必经的关键历练。
>

### 死锁（Deadlock）
死锁是极其有害的，我们必须强调：<font style="background-color:#FBF5CB;">理解并发与并行的区别（参见本章最后一节）对于掌握如何避免死锁至关重要</font>。

<font style="background-color:#E8F7CF;">当两个或多个操作（进程、线程、内核等）相互阻塞，各自等待对方释放资源或完成任务时，就会陷入死锁状态，导致系统停滞不前</font>。换言之，我们的应用程序将永远无法完成。每次使用等待、同步或锁机制时，都可能引发死锁。缺乏同步可能导致死锁，但更常见的情况是引发竞态条件（参见前文）。

<font style="background-color:#FBE4E7;">死锁往往难以调试</font>，我们将在本章末尾"并发与并行"章节中再次探讨这一问题。

> 第4章将告诉我们“lambda表达式并非有害”。为了熟练运用dpC++、SYCL和现代C++，我们应当从容地使用lambda表达式。
>

### C++ Lambda 表达式（C++ Lambda Expressions）
<font style="background-color:#FBE4E7;">现代C++中被并行编程技术广泛使用的特性之一是</font>`<font style="background-color:#FBE4E7;">lambda表达式</font>`。内核（在设备上运行的代码）可以通过多种方式表达，最常见的是lambda表达式。第10章将讨论内核可采取的各种形式，包括lambda表达式。此处我们回顾C++的lambda表达式，并补充一些关于如何用其定义内核的注意事项。待我们在后续章节学习更多SYCL知识后，第10章会进一步展开内核相关内容的探讨。

图1-3中的代码包含一个lambda表达式。我们可以通过其标志性的[=]起始符号识别它。在C++中，lambda表达式以方括号开头，右括号前的信息表示如何捕获在lambda内使用但未显式作为参数传递的变量。对于SYCL中的内核，必须采用值捕获方式，即方括号内需包含等号。

<font style="background-color:#E8F7CF;">C++11引入了对lambda表达式的支持</font>。它们<font style="background-color:#CEF5F7;">用于创建匿名函数对象（尽管我们可以将其赋值给命名变量），并能够捕获外围作用域的变量</font>。C++ lambda表达式的基本语法是：

```cpp
[ capture-list ] ( params ) -> ret { body }
```

其中

• 捕获列表（capture-list）是以逗号分隔的捕获项集合。  
通过将变量名列入捕获列表即可按值捕获该变量。若在变量名前添加"&"前缀（例如&v）则可按引用捕获。  
此外存在适用于所有作用域内自动变量的简写形式：  

+ [=] 按值捕获函数体内使用的所有自动变量，并按引用捕获当前对象；  
+ [&] 按引用捕获函数体内使用的所有自动变量及当前对象；  
+ [] 不进行任何捕获。

  在SYCL中，由于内核函数禁止按引用捕获变量，因此始终使用[=]形式。根据C++标准，lambda表达式不捕获全局变量。非全局静态变量仅当其被声明为const时才可在内核中使用。上述限制条款确保内核在不同设备架构与实现中保持行为一致性。

• params 是函数形参列表，与具名函数相同。SYCL 允许通过参数标识内核要处理的元素：可以是唯一ID（一维）或二维/三维ID。这些内容将在第四章详述。   
• ret 表示返回类型。若未指定 ->ret，则根据返回语句自动推断。若无返回语句或返回值为空，则返回类型为 void。SYCL 内核的返回类型必须始终为 void，因此无需使用此语法为内核指定返回类型。   
• body 是函数体。对于 SYCL 内核，其代码存在若干限制（参见本章前述"内核代码"章节）。  

 图1-4展示了一个C++ lambda表达式，该表达式通过值捕获变量i，通过引用捕获变量j，并接收参数k0和以引用方式传递的参数l0。运行该示例将产生如图1-5所示的输出。  

```cpp
    int i = 1, j = 10, k = 100, l = 1000;

    auto lambda = [i, &j](int k0, int& l0) -> int {
        j = 2 * j;
        k0 = 2 * k0;
        l0 = 2 * l0;
        return i + j + k0 + l0;
    };

    print_values(i, j, k, l);
    std::cout << "First call returned " << lambda(k, l) << "\n";
    print_values(i, j, k, l);
    std::cout << "Second call returned " << lambda(k, l) << "\n";
    print_values(i, j, k, l);
```

![图1-5. 图1-4中lambda表达式演示代码的输出](https://cdn.nlark.com/yuque/0/2025/png/33636091/1745578541483-4bd0d08e-6c4f-43e5-bfd2-a06c691f00a4.png)

我们可以将lambda表达式视为函数对象的实例，但编译器会为我们生成类定义。例如，前文示例中使用的lambda表达式就类似于图1-6所示的类实例。在任何使用C++ lambda表达式的地方，都可以用图1-6所示的函数对象实例来替代。  

每当我们定义一个函数对象时，都需要为其指定名称（例如图1-6中的`Functor`）。而内联表达的lambda表达式（如图1-4所示）是匿名的，因为它们不需要名称。

```cpp
class Functor {
public:
    Functor(int i, int &j) : my_i{i}, my_jRef{j} {}

    int operator()(int k0, int &l0) {
        my_jRef = 2 * my_jRef;
        k0 = 2 * k0;
        l0 = 2 * l0;
        return my_i + my_jRef + k0 + l0;
    }

private:
    int my_i;
    int &my_jRef;
};
```

### 功能可移植性与性能可移植性（Functional Portability and Performance Portability）
可移植性是使用C++与SYCL的关键目标，但没有任何事物能确保其实现。语言和编译器所能做的，只是在我们有意实现应用可移植性时略微降低难度。诚然，更高层次（更抽象）的编程范式——如领域特定语言、库和框架——往往能提供更强的可移植性，这主要源于它们允许采用非硬性规定的编程方式。由于本书聚焦于C++中的数据并行编程，我们默认开发者追求更强的控制力，而随之而来的则是需要<font style="background-color:#FBE4E7;">更深入理解代码编写对可移植性的影响</font>。

<font style="background-color:#F9EFCD;">可移植性</font>是一个复杂的课题，既包含<font style="background-color:#E8F7CF;">功能可移植性概念</font>，也涵盖<font style="background-color:#E8F7CF;">性能可移植性</font>。<font style="background-color:#CEF5F7;">功能可移植性要求程序能在各类平台上等效编译运行</font>；<font style="background-color:#CEF5F7;">性能可移植性则追求程序在多样化平台上获得合理性能表现</font>。虽然这一定义较为宽泛，但其反面或许更为明晰——我们不愿编写仅在单一平台运行极快、却在其他平台异常缓慢的程序。事实上，我们更<font style="background-color:#FBF5CB;">希望程序能充分挖掘任何运行平台的潜力</font>。鉴于异构系统中设备的多样性，实现性能可移植性需要程序员付出大量努力。

所幸，<font style="background-color:#FBE4E7;">SYCL定义了一种能够提升性能可移植性的编程方式</font>。首先，<font style="background-color:#FBF5CB;">通用内核可在所有设备上运行</font>。在少数情况下，这种通用性可能已足够。更常见的做法是，<font style="background-color:#FBE4E7;">针对不同类型的设备编写多个重要内核版本</font>。具体而言，一个内核可能包含通用GPU版本和通用CPU版本。偶尔，我们可能需要为特定设备（如某款具体GPU）定制内核。此时，既可编写多个版本分别适配不同GPU型号，也可通过参数化设计，利用GPU特性动态调整内核运行方式以适应目标GPU。  

尽管作为程序员，我们需要自行设计实现性能可移植性的有效方案，但SYCL定义了一系列编程结构来支持我们实施这类方案。如前所述，可通过分层方式构建能力——<font style="background-color:#FBF5CB;">首先编写适用于所有设备的通用内核，再根据需要逐步引入更专用的内核版本</font>。这听起来很理想，但程序的整体流程同样会产生深远影响，因为数据移动与算法选择同样至关重要。了解第一章"引言"第28节所述内容后，就能明白为何无人能断言"采用SYCL（或其他编程方案）的C++语言可彻底解决性能可移植性问题"。然而毋庸置疑，它确实是我们应对这些挑战时工具箱中的重要利器。  

##  并发 vs. 并行(Concurrency vs. Parallelism)
虽然“并发”（concurrent）和“并行”（parallel）这两个术语有时会被误解为同义词，但它们并非必然等同。由于不同文献对这些概念的定义鲜有共识，相关讨论往往更趋复杂。

参考以下来自Sun Microsystems《多线程编程指南》的定义：  

• **并发（Concurrency）**：当至少两个线程正在推进时存在的一种状态  

• **并行（Parallelism）**：当两个线程同时执行时存在的一种状态

要透彻理解这些概念之间的差异，我们需要从直观层面把握其核心要义。以下几点观察有助于形成这种理解：

• 并行执行可以模拟实现：即便硬件不支持同时处理多任务，软件仍可通过多路复用技术模拟同步处理多个任务。多路复用正是并发非并行的典型范例。

 • 硬件资源是有限的：硬件永远不可能无限“宽广”，因为硬件始终具有有限数量的执行资源（如处理器、核心、执行单元）。当硬件能够使用专用资源执行每个线程时，我们便实现了并发与并行。  

当我们程序员说"同时执行X、Y和Z"时，通常并不真正关心硬件是否支持并发或并行。我们大概不希望程序（包含三个任务）在仅能同时运行两个任务的机器上无法启动。我们更倾向于让尽可能多的任务并行处理，通过循环分批执行所有任务直至完成。  

但有些时候，我们确实需要谨慎对待。思维中的谬误可能引发灾难性后果（例如"死锁"）。假设我们修改上一段的示例，让任务（X、Y或Z）最后执行的操作变成"等待所有任务完成"。当任务数量未超出硬件限制时，程序仍能正常运行。但若将任务拆分为若干批次执行，第一批次中的某个任务就会陷入无限等待。更糟糕的是，这将导致整个应用程序无法完成。  

这是一个常见的易犯错误，正因如此我们才要重点强调这些概念。即便是经验丰富的程序员也必须集中精力才能避免此类问题——我们都会发现，当思维出现疏漏时仍需调试纠错。这些概念并不简单，C++规范甚至用冗长的章节详述了线程能确保执行进度的精确条件。在本入门章节中，我们所能做的就是尽可能强调理解这些概念的重要性。

培养对这些概念的直观理解对于高效开发异构和加速系统至关重要。我们都需要给自己时间逐步建立这种直觉——它并非一蹴而就。

## 总结（Summary）
本章介绍了理解C++与SYCL所需的关键术语，并回顾了并行编程和C++中对SYCL至关重要的核心概念。第二、三、四章将深入探讨使用C++与SYCL进行数据并行编程的三大要素：为设备分配计算任务（向其传送待执行代码）、提供数据资源（向其传送待处理数据）、以及编写核心代码的方法（内核构建）。

